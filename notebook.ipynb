{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdYv4sl-NNUW"
      },
      "source": [
        "# Install Dependecies Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq1wjy4aQrF-"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_OOO_GQNRck"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aSKGVL7xXPT5"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWYLg_mNNTDz"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKq25D411vCG",
        "outputId": "85d7186a-2fed-49c8-d7ff-e8c80a03da86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 221MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8x.pt\")\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ov70aJsNU83"
      },
      "source": [
        "# Load Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KdIzWntP3u4T"
      },
      "outputs": [],
      "source": [
        "# directory video\n",
        "SOURCE_VIDEO_PATH = \"assets/toll_gate.mp4\"\n",
        "\n",
        "# directory to saving video result detection and count\n",
        "RESULT_VIDEO_PATH = \"assets/toll_gate-result.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bc2OQiR7Xu"
      },
      "source": [
        "# Detect and Counting Vehicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P6E9gidc1yHA"
      },
      "outputs": [],
      "source": [
        "CLASS_NAMES_DICT = model.model.names\n",
        "selected_classes = [2,5] # car,bus\n",
        "\n",
        "# line for counting vehicle\n",
        "LINE_START = sv.Point(10, 155)\n",
        "LINE_END = sv.Point(560, 275)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBpr3K1l13U_"
      },
      "outputs": [],
      "source": [
        "# read video frame by frame\n",
        "video_info = sv.VideoInfo.from_video_path(video_path=SOURCE_VIDEO_PATH)\n",
        "generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH)\n",
        "\n",
        "# load tracker using byte_track\n",
        "tracker = sv.ByteTrack()\n",
        "line_zone = sv.LineZone(start=LINE_START, end=LINE_END,\n",
        "                        triggering_anchors=[sv.Position.TOP_RIGHT])\n",
        "\n",
        "box_annotator = sv.BoxAnnotator() # bounding box\n",
        "trace_annotator = sv.TraceAnnotator() # tracer vehicle\n",
        "\n",
        "# annotate line and text\n",
        "line_zone_annotator = sv.LineZoneAnnotator(color=sv.Color.YELLOW,\n",
        "                                           text_thickness=1, text_offset=14,\n",
        "                                           text_scale=0.6, text_padding=15,\n",
        "                                           custom_in_text=\"Vehicle Numbers\",\n",
        "                                           display_out_count=False)\n",
        "\n",
        "# annotate label detection\n",
        "label_annotator = sv.LabelAnnotator(text_color=sv.Color.RED,\n",
        "                                    border_radius=3)\n",
        "\n",
        "with sv.VideoSink(target_path=RESULT_VIDEO_PATH, video_info=video_info) as sink:\n",
        "  for frame in tqdm(generator, total=video_info.total_frames):\n",
        "    results = model.track(frame, persist=True, classes=[selected_classes])[0] # predict\n",
        "\n",
        "    detections = sv.Detections.from_ultralytics(results) # convert to supervision\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)] # filter class\n",
        "    detections = tracker.update_with_detections(detections) # update tracker\n",
        "    line_zone.trigger(detections) # trigger line\n",
        "\n",
        "    # format custom labels\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "        for tracker_id, confidence, class_id in zip(detections.tracker_id, detections.confidence, detections.class_id)\n",
        "    ]\n",
        "\n",
        "    annotated_frame = trace_annotator.annotate(scene=frame.copy(),detections=detections) # tracer vehicle\n",
        "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections) # bounding box\n",
        "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels) # label detection\n",
        "    annotated_frame = line_zone_annotator.annotate(annotated_frame, line_counter=line_zone) # annotate line and text\n",
        "\n",
        "    sink.write_frame(annotated_frame) # write video result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
